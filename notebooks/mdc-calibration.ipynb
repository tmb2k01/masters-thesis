{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4338c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.models.high_level_model import HighLevelModel\n",
    "from src.calibration.calibration import calibration\n",
    "from src.data.multi_output_dataset import MultiOutputDataModule\n",
    "from src.models.model_utils import convert_multitask_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8d29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDC_COLOR = 12\n",
    "MDC_TYPE = 11\n",
    "MDC_TASK_NUM_CLASSES = [MDC_COLOR, MDC_TYPE]\n",
    "root_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0ce9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HighLevelModel.load_from_checkpoint(\n",
    "    \"models/mdc-high-level-model.ckpt\",\n",
    "    map_location=\"cpu\",\n",
    "    task_num_classes=MDC_TASK_NUM_CLASSES,\n",
    ")\n",
    "datamodule = MultiOutputDataModule(\n",
    "    root_dir=root_dir,\n",
    "    task_num_classes=MDC_TASK_NUM_CLASSES,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4559f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/tmb2k01/masters-thesis/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 76/76 [00:11<00:00,  6.62it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer = pl.Trainer(accelerator=\"gpu\")\n",
    "\n",
    "calib_preds = trainer.predict(model, dataloaders=datamodule.calib_dataloader())\n",
    "calib_preds = convert_multitask_preds(calib_preds)\n",
    "true_labels = [labels for _, labels in datamodule.datasets[\"calib\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d579cee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m q_hats = \u001b[43mcalibration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalib_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhigh_level\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHighLevelModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/masters-thesis/src/calibration/calibration.py:78\u001b[39m, in \u001b[36mcalibration\u001b[39m\u001b[34m(scores, true_labels, high_level, alpha, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m calibration_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m q_hats:\n\u001b[32m     76\u001b[39m             q_hats[calibration_type] = {}\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         q_hats[calibration_type][nonconformity_name] = \u001b[43mcalibration_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnonconformity_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnonconformity_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m q_hats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/masters-thesis/src/calibration/calibration_utils.py:53\u001b[39m, in \u001b[36mcompute_qhat_scp_global\u001b[39m\u001b[34m(nonconformity_scores, true_labels, alpha, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_qhat_scp_global\u001b[39m(\n\u001b[32m     36\u001b[39m     nonconformity_scores: Union[List[np.ndarray], np.ndarray],\n\u001b[32m     37\u001b[39m     true_labels: np.ndarray,\n\u001b[32m     38\u001b[39m     alpha: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     39\u001b[39m     **kwargs,\n\u001b[32m     40\u001b[39m ):\n\u001b[32m     41\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    Compute the q-hat value for the Standard Conformal Prediction global calibration method.\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m        float: The global standard q-hat value.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mnonconformity_scores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m     54\u001b[39m         \u001b[32m2\u001b[39m,\n\u001b[32m     55\u001b[39m         \u001b[32m3\u001b[39m,\n\u001b[32m     56\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mNonconformity scores should be 2D or 3D.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m     58\u001b[39m         true_labels.shape[\u001b[32m0\u001b[39m] == nonconformity_scores.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     59\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mMismatch between true_labels and nonconformity_scores dimensions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nonconformity_scores.shape) == \u001b[32m3\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "q_hats = calibration(\n",
    "    calib_preds,\n",
    "    true_labels,\n",
    "    high_level=isinstance(model, HighLevelModel),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
